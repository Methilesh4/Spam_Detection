{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHxfnZV17AGx"
      },
      "source": [
        "*italicized text*# **stack machine learning models in Python**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOtnY-sWpwiW",
        "outputId": "134d8990-3c46-4db4-aa80-e9c3454e39b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "escsGkWFtzVj"
      },
      "source": [
        "# **Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-NFn_UOtuVE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "b1 = pd.read_csv('/content/drive/MyDrive/1.csv',encoding='latin')\n",
        "#b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq70jVt7rGW8",
        "outputId": "dbc128b9-9aa1-440c-d010-83f9b0442b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roxPlm8ShaJs",
        "outputId": "bb87db26-a242-4af2-fee4-d52587eb538c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in the Class set:  ['ham' 'spam']\n",
            "Number of ham messages in data set: 4825\n",
            "Number of spam messages in data set: 747\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "data = pd.read_csv('/content/drive/MyDrive/1.csv',encoding='latin')\n",
        "\n",
        "data.rename(columns={'v1':'Class','v2':'Text'},inplace=True)\n",
        "data['numClass'] = data['Class'].map({'ham':0, 'spam':1})\n",
        "data['Count']=0\n",
        "for i in np.arange(0,len(data.Text)):\n",
        "    data.loc[i,'Count'] = len(data.loc[i,'Text'])\n",
        "\n",
        "# Unique values in target set\n",
        "print(\"Unique values in the Class set: \", data.Class.unique())\n",
        "\n",
        "ham  = data[data.numClass == 0]\n",
        "ham_count  = pd.DataFrame(pd.value_counts(ham['Count'],sort=True).sort_index())\n",
        "print(\"Number of ham messages in data set:\", ham['Class'].count())\n",
        "#print(\"Ham Count value\", ham_count['Count'].count())\n",
        "\n",
        "spam = data[data.numClass == 1]\n",
        "spam_count = pd.DataFrame(pd.value_counts(spam['Count'],sort=True).sort_index())\n",
        "print(\"Number of spam messages in data set:\", spam['Class'].count())\n",
        "#print(\"Spam Count value:\", spam_count['Count'].count())\n",
        "\n",
        "\n",
        "#Removing stopwords of English\n",
        "stopset = set(stopwords.words(\"english\"))\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=stopset,binary=True)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(data.Text)\n",
        "# Extract target column 'Class'\n",
        "y = data.numClass\n",
        "#X = b1['v2'].copy()\n",
        "\n",
        "#X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyAOBjc5hwf_"
      },
      "outputs": [],
      "source": [
        "#y = b1['v1'].copy()\n",
        "#y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9vHDORkwJE5",
        "outputId": "91550631-8e37-43c5-af34-f646a2d2b727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572, 8672)\n"
          ]
        }
      ],
      "source": [
        "# Remove low variance features\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selection = VarianceThreshold(threshold=(0.1))\n",
        "\n",
        "#X = selection.fit_transform(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJSV0WJQpIDX"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpns5FPdaQgq"
      },
      "outputs": [],
      "source": [
        "# Data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGQmqYf2ObLw",
        "outputId": "5ec75b43-559d-4eb8-ac1d-58a2cc7bbe01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4457, 8672), (1115, 8672))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwYQXxo7Ox0r"
      },
      "outputs": [],
      "source": [
        "#y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVoIXOmNPWOn"
      },
      "outputs": [],
      "source": [
        "#y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UpZfDRyvb5t"
      },
      "source": [
        "# **Build Classification models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8yCRtbQu5-F"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswMOe9Y26Nm"
      },
      "source": [
        "**K nearest neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fI6Ni6i3EAy",
        "outputId": "9ee56f9f-3294-4a29-c7bd-2be05c1021b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9557998653803007\n",
            "- MCC: 0.7987484169602704\n",
            "- F1 score: 0.9519918525783085\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9327354260089686\n",
            "- MCC: 0.6788689166658943\n",
            "- F1 score: 0.922680930644091\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(3) # Define classifier\n",
        "knn.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = knn.predict(X_train)\n",
        "y_test_pred = knn.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "knn_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "knn_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % knn_train_accuracy)\n",
        "print('- MCC: %s' % knn_train_mcc)\n",
        "print('- F1 score: %s' % knn_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % knn_test_accuracy)\n",
        "print('- MCC: %s' % knn_test_mcc)\n",
        "print('- F1 score: %s' % knn_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tus32H-i42PT"
      },
      "source": [
        "**Decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3YJF0rz44Ar",
        "outputId": "76258adc-cd2d-483d-bd17-b19d89d0f1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9524343728965672\n",
            "- MCC: 0.783511238807641\n",
            "- F1 score: 0.950443759746196\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9461883408071748\n",
            "- MCC: 0.7535542427780467\n",
            "- F1 score: 0.9439737386730414\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=5) # Define classifier\n",
        "dt.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = dt.predict(X_train)\n",
        "y_test_pred = dt.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "dt_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "dt_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % dt_train_accuracy)\n",
        "print('- MCC: %s' % dt_train_mcc)\n",
        "print('- F1 score: %s' % dt_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % dt_test_accuracy)\n",
        "print('- MCC: %s' % dt_test_mcc)\n",
        "print('- F1 score: %s' % dt_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXd2iTxuviDb"
      },
      "source": [
        "**Random forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4iahxJWvhVu",
        "outputId": "4d1d6913-0dea-4fc8-efce-82e9f68def1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9977563383441777\n",
            "- MCC: 0.9903212439923711\n",
            "- F1 score: 0.9977483310440378\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9730941704035875\n",
            "- MCC: 0.8797590905240871\n",
            "- F1 score: 0.9719868693365206\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10) # Define classifier\n",
        "rf.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = rf.predict(X_train)\n",
        "y_test_pred = rf.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "rf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "rf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % rf_train_accuracy)\n",
        "print('- MCC: %s' % rf_train_mcc)\n",
        "print('- F1 score: %s' % rf_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % rf_test_accuracy)\n",
        "print('- MCC: %s' % rf_test_mcc)\n",
        "print('- F1 score: %s' % rf_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_H6KkezwfH0"
      },
      "source": [
        "**Neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06mNcVuUwrpi",
        "outputId": "5c27d79c-c548-4052-e677-13931a31bc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9934933811981154\n",
            "- MCC: 0.9717937814422039\n",
            "- F1 score: 0.9934295820318156\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.979372197309417\n",
            "- MCC: 0.9085893982640185\n",
            "- F1 score: 0.9787702598452416\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(alpha=1, max_iter=1000)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = mlp.predict(X_train)\n",
        "y_test_pred = mlp.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "mlp_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "mlp_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % mlp_train_accuracy)\n",
        "print('- MCC: %s' % mlp_train_mcc)\n",
        "print('- F1 score: %s' % mlp_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % mlp_test_accuracy)\n",
        "print('- MCC: %s' % mlp_test_mcc)\n",
        "print('- F1 score: %s' % mlp_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPP95Rpyt8go"
      },
      "source": [
        "# **Build Stacked model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO_qR3303OUp",
        "outputId": "767c6fb6-54de-4b16-cc3e-35dc62855318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9993269015032533\n",
            "- MCC: 0.9971009853541186\n",
            "- F1 score: 0.9993261859597724\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9874439461883409\n",
            "- MCC: 0.9449564464078356\n",
            "- F1 score: 0.9872192857245174\n"
          ]
        }
      ],
      "source": [
        "# Define estimators\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "estimator_list = [\n",
        "    ('knn',knn),\n",
        "\n",
        "    ('dt',dt),\n",
        "    ('rf',rf),\n",
        "    ('mlp',mlp)\n",
        "]\n",
        "\n",
        "# Build stack model\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "# Train stacked model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = stack_model.predict(X_train)\n",
        "y_test_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
        "print('- MCC: %s' % stack_model_train_mcc)\n",
        "print('- F1 score: %s' % stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
        "print('- MCC: %s' % stack_model_test_mcc)\n",
        "print('- F1 score: %s' % stack_model_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Az-v5Tmden0"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr_A9dIUdhes"
      },
      "outputs": [],
      "source": [
        "acc_train_list = {'knn':knn_train_accuracy,\n",
        "\n",
        "'dt': dt_train_accuracy,\n",
        "'rf': rf_train_accuracy,\n",
        "'mlp': mlp_train_accuracy,\n",
        "'stack': stack_model_train_accuracy}\n",
        "\n",
        "mcc_train_list = {'knn':knn_train_mcc,\n",
        "'dt': dt_train_mcc,\n",
        "'rf': rf_train_mcc,\n",
        "'mlp': mlp_train_mcc,\n",
        "'stack': stack_model_train_mcc}\n",
        "\n",
        "f1_train_list = {'knn':knn_train_f1,\n",
        "'dt': dt_train_f1,\n",
        "'rf': rf_train_f1,\n",
        "'mlp': mlp_train_f1,\n",
        "'stack': stack_model_train_f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrUnYrWj3p-s",
        "outputId": "f3749ee8-95fc-49bd-8c1a-b680fc904bea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'knn': 0.7987484169602704,\n",
              " 'dt': 0.783511238807641,\n",
              " 'rf': 0.9903212439923711,\n",
              " 'mlp': 0.9717937814422039,\n",
              " 'stack': 0.9971009853541186}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mcc_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPIcIXOte2fC",
        "outputId": "f907e328-8c49-4cc5-ed70-8ac69f6bbb38",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Accuracy       MCC        F1\n",
            "knn    0.955800  0.798748  0.951992\n",
            "dt     0.952434  0.783511  0.950444\n",
            "rf     0.997756  0.990321  0.997748\n",
            "mlp    0.993493  0.971794  0.993430\n",
            "stack  0.999327  0.997101  0.999326\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
        "mcc_df = pd.DataFrame.from_dict(mcc_train_list, orient='index', columns=['MCC'])\n",
        "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
        "df = pd.concat([acc_df, mcc_df, f1_df], axis=1)\n",
        "df\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLf3aAfRpIDd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVz6u1opkzyw"
      },
      "outputs": [],
      "source": [
        "df.to_csv('results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzNDRR-7pIDd",
        "outputId": "d1f7b412-c31a-4d21-c516-5fb1d7ab5236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/saved_models/stack.sav']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "joblib.dump(stack_model, '/content/drive/MyDrive/saved_models/stack.sav')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq9ClEaIH9PJ",
        "outputId": "bbbc6619-f8ad-45c3-a24f-ee9fc81992d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Lgitimate message: FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/1.csv',encoding='latin')\n",
        "\n",
        "data.rename(columns={'v1':'Class','v2':'Text'},inplace=True)\n",
        "data['numClass'] = data['Class'].map({'ham':0, 'spam':1})\n",
        "data['Count']=0\n",
        "for i in np.arange(0,len(data.Text)):\n",
        "    data.loc[i,'Count'] = len(data.loc[i,'Text'])\n",
        "\n",
        "# Unique values in target set\n",
        "\n",
        "\n",
        "ham  = data[data.numClass == 0]\n",
        "ham_count  = pd.DataFrame(pd.value_counts(ham['Count'],sort=True).sort_index())\n",
        "\n",
        "#print(\"Ham Count value\", ham_count['Count'].count())\n",
        "\n",
        "spam = data[data.numClass == 1]\n",
        "spam_count = pd.DataFrame(pd.value_counts(spam['Count'],sort=True).sort_index())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Removing stopwords of English\n",
        "stopset = set(stopwords.words(\"english\"))\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=stopset, binary=True)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "A = vectorizer.fit_transform(data.Text)\n",
        "new_text = \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\"\n",
        "new_text_vectorized = vectorizer.transform([new_text])\n",
        "loaded_model = joblib.load('/content/drive/MyDrive/saved_models/stack.sav')\n",
        "# result = loaded_model.score(X_test, y_test)\n",
        "dd=loaded_model.predict(new_text_vectorized)\n",
        "print(dd)\n",
        "# tac=dd[14:20]\n",
        "# p=10\n",
        "\n",
        "# for i in tac:\n",
        "if i==1:\n",
        "    print(\"Spam message:\",new_text,\"\\n\")\n",
        "else:\n",
        "    print(\"Lgitimate message:\",new_text,\"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vck3DAJhVgF6",
        "outputId": "8a20bd7b-a375-44db-ab6d-eca3dc79c583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import*\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "s = Flask(__name__)\n",
        "\n",
        "\n",
        "\n",
        "@s.route(\"/spam_or_ham\", methods=[\"GET\"])\n",
        "def spam():\n",
        "            data = pd.read_csv('/content/drive/MyDrive/1.csv',encoding='latin')\n",
        "\n",
        "            data.rename(columns={'v1':'Class','v2':'Text'},inplace=True)\n",
        "            data['numClass'] = data['Class'].map({'ham':0, 'spam':1})\n",
        "            data['Count']=0\n",
        "            for i in np.arange(0,len(data.Text)):\n",
        "                       data.loc[i,'Count'] = len(data.loc[i,'Text'])\n",
        "\n",
        "            # Unique values in target set\n",
        "\n",
        "\n",
        "            ham  = data[data.numClass == 0]\n",
        "            ham_count  = pd.DataFrame(pd.value_counts(ham['Count'],sort=True).sort_index())\n",
        "\n",
        "            #print(\"Ham Count value\", ham_count['Count'].count())\n",
        "\n",
        "            spam = data[data.numClass == 1]\n",
        "            spam_count = pd.DataFrame(pd.value_counts(spam['Count'],sort=True).sort_index())\n",
        "\n",
        "            stopset = set(stopwords.words(\"english\"))\n",
        "\n",
        "            vectorizer = CountVectorizer(stop_words=stopset, binary=True)\n",
        "            vectorizer = CountVectorizer()\n",
        "            new_text = \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\"\n",
        "\n",
        "            A = vectorizer.fit_transform(data.Text)\n",
        "            new_text_vectorized = vectorizer.transform([new_text])\n",
        "            loaded_model = joblib.load(\"/content/drive/MyDrive/saved_models/stack.sav\")\n",
        "\n",
        "            dd=loaded_model.predict(A)\n",
        "            print(dd)\n",
        "\n",
        "            if dd==1:\n",
        "                print(\"Spam message:\",new_text,\"\\n\")\n",
        "                return render_template(\"hi.html\",result=\"Spam message\")\n",
        "            else:\n",
        "                print(\"Lgitimate message:\",new_text,\"\\n\")\n",
        "                return render_template(\"hi.html\",result=\"Lgitimate message\")\n",
        "if __name__ == \"__main__\":\n",
        "    s.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}